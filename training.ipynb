{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LOADING DATA & PRETRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "import math\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "model_ckpt = 'facebook/bart-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
        "\n",
        "dataset = load_dataset('csv', data_files={'train': \"./data/train.csv\", 'test': \"./data/test.csv\", 'validate': \"./data/validation.csv\"})\n",
        "\n",
        "dataset['validate'] = dataset['validate'].select(range(5000))\n",
        "\n",
        "def filter_empty_rows(example):\n",
        "    return all(value for value in example.values())\n",
        "\n",
        "# Filter the dataset using the custom filtering function\n",
        "dataset = dataset.filter(filter_empty_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Data Collator.\n",
        "\n",
        "def get_feature(batch):\n",
        "  \"\"\"\n",
        "  This collarate the content of the inputs to the abstract of the result using the formatted encodings.\n",
        "  \"\"\"\n",
        "  encodings = tokenizer(batch['Content'], text_target=batch['Abstract'],\n",
        "                        max_length=1024, truncation=True)\n",
        "\n",
        "  encodings = {'input_ids': encodings['input_ids'],\n",
        "               'attention_mask': encodings['attention_mask'],\n",
        "               'labels': encodings['labels']}\n",
        "\n",
        "  return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 23459/23459 [00:39<00:00, 587.12 examples/s]\n",
            "Map: 100%|██████████| 2933/2933 [00:05<00:00, 565.23 examples/s]\n",
            "Map: 100%|██████████| 5000/5000 [00:08<00:00, 581.28 examples/s]\n"
          ]
        }
      ],
      "source": [
        "data = dataset.map(get_feature, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = ['input_ids', 'labels', 'attention_mask']\n",
        "data.set_format(type='torch', columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FINETUNING "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './model/bart_vietnews_full',\n",
        "    num_train_epochs=1,                         # Number of training epochs. Here, it's set to 1. (>1 leads to longer training time)\n",
        "    warmup_steps = 500,                         # Number of steps for the learning rate warmup.\n",
        "    per_device_train_batch_size=4,              # Batch size per GPU/TPU core/CPU for training.\n",
        "    per_device_eval_batch_size=4,               # Batch size per GPU/TPU core/CPU for evaluation.\n",
        "    weight_decay = 0.01,                        # Weight decay for regularization to prevent overfitting.\n",
        "    logging_steps = 10,                         # Log training information every 10 steps.\n",
        "    evaluation_strategy = 'steps',              # Evaluation strategy to use: 'steps' (evaluation occurs at regular intervals.)\n",
        "    eval_steps=500,                             # Number of update steps between evaluations.\n",
        "    save_steps=1e6,                             # Number of update steps before saving the model. \n",
        "    gradient_accumulation_steps=16              # Number of update steps to accumulate the gradients before performing a backward/update pass.\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, \n",
        "                  args=training_args, \n",
        "                  tokenizer=tokenizer, \n",
        "                  data_collator=data_collator,          \n",
        "                  train_dataset = data['train'], \n",
        "                  eval_dataset = data['test'])\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [221:37:05<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8517, 'grad_norm': 0.8825595378875732, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [223:19:39<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8371, 'grad_norm': 0.8581170439720154, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [225:01:13<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8328, 'grad_norm': 0.9053831100463867, 'learning_rate': 3e-06, 'epoch': 0.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [226:42:14<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.822, 'grad_norm': 0.8076022267341614, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [228:20:31<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8203, 'grad_norm': 0.8420484066009521, 'learning_rate': 5e-06, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [229:59:52<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8224, 'grad_norm': 0.8437042236328125, 'learning_rate': 6e-06, 'epoch': 0.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [231:40:09<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8391, 'grad_norm': 0.8439734578132629, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.19}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [233:19:12<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8343, 'grad_norm': 0.8412922024726868, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [234:59:28<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8084, 'grad_norm': 0.8188759088516235, 'learning_rate': 9e-06, 'epoch': 0.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [236:40:42<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8082, 'grad_norm': 0.827989935874939, 'learning_rate': 1e-05, 'epoch': 0.27}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [238:20:18<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8384, 'grad_norm': 0.8899693489074707, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [240:01:20<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8343, 'grad_norm': 0.9427409768104553, 'learning_rate': 1.2e-05, 'epoch': 0.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [241:43:02<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8215, 'grad_norm': 0.8673585653305054, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.35}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [243:23:43<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8243, 'grad_norm': 0.8377318382263184, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [245:07:05<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8309, 'grad_norm': 0.9342151284217834, 'learning_rate': 1.5e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [246:49:03<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8101, 'grad_norm': 0.9947242736816406, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.44}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [248:30:36<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.829, 'grad_norm': 0.9735804796218872, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [250:08:14<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8303, 'grad_norm': 0.8877909779548645, 'learning_rate': 1.8e-05, 'epoch': 0.49}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [251:50:48<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8123, 'grad_norm': 0.951964795589447, 'learning_rate': 1.9e-05, 'epoch': 0.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [253:29:46<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8565, 'grad_norm': 1.0261504650115967, 'learning_rate': 2e-05, 'epoch': 0.55}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [255:08:27<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8377, 'grad_norm': 0.8931803107261658, 'learning_rate': 2.1e-05, 'epoch': 0.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [256:48:41<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8194, 'grad_norm': 0.938022255897522, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [258:29:38<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8514, 'grad_norm': 1.01076078414917, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.63}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [260:10:05<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8252, 'grad_norm': 0.9052630066871643, 'learning_rate': 2.4e-05, 'epoch': 0.65}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [261:52:43<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8386, 'grad_norm': 0.8922455310821533, 'learning_rate': 2.5e-05, 'epoch': 0.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [263:32:04<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8496, 'grad_norm': 0.8775729537010193, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.71}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [265:13:55<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.826, 'grad_norm': 0.9204713702201843, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [266:55:44<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8419, 'grad_norm': 0.9492039680480957, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.76}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [268:36:29<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8258, 'grad_norm': 0.8842914700508118, 'learning_rate': 2.9e-05, 'epoch': 0.79}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [270:15:42<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8361, 'grad_norm': 0.9559916257858276, 'learning_rate': 3e-05, 'epoch': 0.82}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [271:54:46<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8334, 'grad_norm': 0.9391863942146301, 'learning_rate': 3.1e-05, 'epoch': 0.85}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [273:38:19<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8426, 'grad_norm': 0.9424452781677246, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [275:20:14<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.818, 'grad_norm': 1.0462888479232788, 'learning_rate': 3.3e-05, 'epoch': 0.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [277:02:17<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8346, 'grad_norm': 1.0115809440612793, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.93}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [278:42:59<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8171, 'grad_norm': 0.9955885410308838, 'learning_rate': 3.5e-05, 'epoch': 0.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            " 72%|███████▏  | 936/1309 [280:24:09<64:05:24, 618.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8446, 'grad_norm': 1.0332105159759521, 'learning_rate': 3.6e-05, 'epoch': 0.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \n",
            "100%|██████████| 366/366 [61:30:02<00:00, 604.93s/it]s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 221402.9168, 'train_samples_per_second': 0.106, 'train_steps_per_second': 0.002, 'train_loss': 0.8309862027402783, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=366, training_loss=0.8309862027402783, metrics={'train_runtime': 221402.9168, 'train_samples_per_second': 0.106, 'train_steps_per_second': 0.002, 'total_flos': 5.075944773609062e+16, 'train_loss': 0.8309862027402783, 'epoch': 0.99846547314578})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model('./model/bart_vietnews_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EXAMPLE USAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'summary_text': 'Phát hiện nhóm \"bay lắc\" gồm 12 dân chơi tại một khu đô thị cao cấp của Công an TP Hải Phòng.'}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pipe = pipeline('summarization', model='./model/bart_vietnews_model')\n",
        "\n",
        "custom_dialogue=\"\"\"\n",
        "Ngày 7-4, một lãnh đạo Công an TP Hải Phòng cho biết Phòng cảnh sát điều tra tội phạm về ma túy Công an TP vừa triệt phá ổ nhóm \"bay lắc\" tại một khu đô thị cao cấp trên địa bàn phường Thượng Lý, quận Hồng Bàng.\n",
        "Thông tin ban đầu, khoảng 23h30 ngày 4-4, các trinh sát Phòng cảnh sát điều tra tội phạm về ma túy đột kích, phát hiện nhóm \"bay lắc\" gồm 12 dân chơi (7 nam, 5 nữ), thu giữ tại hiện trường 0,13g ketamin cùng một số tang vật khác có liên quan.\n",
        "Kết quả giám định phát hiện 9 trường hợp dương tính với ma túy. Cơ quan điều tra sau đó tạm giữ hình sự ba trường hợp, gồm Nguyễn Thị Thanh Huyền (38 tuổi), Bùi Thị Ngọc Bích (36 tuổi) và Vũ Hoàng Cường (42 tuổi, cùng trú Hải Phòng) để điều tra về hành vi \"tổ chức sử dụng trái phép chất ma túy\".\n",
        "Trong đó Bùi Thị Ngọc Bích là nữ cán bộ đang công tác tại Phòng cảnh sát phòng cháy chữa cháy Công an TP Hải Phòng.\n",
        "Ngoài ra, còn một nữ cán bộ khác là V.A. có mặt tại buổi \"bay lắc\" là cán bộ đang công tác tại Công an quận Dương Kinh, TP Hải Phòng.\n",
        "\n",
        "\"\"\"\n",
        "gen_kwargs = {'length_penalty': 1, 'num_beams': 8,'max_length': 1024}\n",
        "\n",
        "\n",
        "print(pipe(custom_dialogue, **gen_kwargs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EVALUATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICHzjvFh791I"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import evaluate\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "rouge = evaluate.load('rouge')\n",
        "gen_sum=[]\n",
        "hum_sum=[]\n",
        "model_name=\"vibart_vietnews\"\n",
        "pipe = pipeline('summarization', model='./model/bart_vietnews_model')\n",
        "gen_kwargs = {'length_penalty': 1, 'num_beams': 8,'max_length': 1024}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "gen_sum=[]\n",
        "for sect in dataset['validate']['Abstract']:\n",
        "    gen = pipe(sect, **gen_kwargs)\n",
        "    gen_sum.append(gen[0]['summary_text'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for title in dataset['validate']['Title']:\n",
        "    hum_sum.append(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = rouge.compute(predictions=gen_sum,references=hum_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new DataFrame from the lists\n",
        "import datetime\n",
        "new_df = pd.DataFrame({\n",
        "    'human': hum_sum,\n",
        "    'generated': gen_sum\n",
        "})\n",
        "x = datetime.datetime.now()\n",
        "time=\"_\".join([model_name,x.strftime(\"%d\"),x.strftime(\"%m\"),x.strftime(\"%Y\"),x.strftime(\"%H\"),x.strftime(\"%M\"),x.strftime(\"%S\")])\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv(\"\".join(['summaries',time,'.csv']), index=False,encoding=\"utf_8_sig\")\n",
        "print(\"Complete: \",results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8xPhRF1t7F6t",
        "FEhas0Ui7PP_",
        "Og2k1ZIA7TiF",
        "PwlQnG_c7d_Z"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
